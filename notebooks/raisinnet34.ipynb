{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "raisinnet34.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHNyn8hnnYEg"
      },
      "source": [
        "# RaisinNet34\n",
        "\n",
        "An exploration of how to adapt the ResNet-34 CNN architecture, and modify the structure of the classification layer. Explores how to transfer learn and freeze the weights for the convolutional layers.\n",
        "\n",
        "The developed ResNet-34 is evaluated on the PyTorch hymenoptera dataset.\n",
        "\n",
        "This notebook is inspired by:\n",
        "- [CS284A CNN example](https://github.com/xhxuciedu/CS284A/blob/master/convolutional_neural_net.ipynb)\n",
        "- [PyTorch transfer learning tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
        "\n",
        "Make sure the runtime type of this notebook has a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cKQqJZenUSS"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils import data\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.models import resnet34, resnet18"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXhlDTznnXul"
      },
      "source": [
        "### Use GPU if Available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm3HLsugoAHx",
        "outputId": "55b3a6ca-e874-472c-cfa9-3d1899ae3958"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPa_1UeUoJ2n"
      },
      "source": [
        "### Download, Transform, and Load Dataset\n",
        "\n",
        "1) Download hymenoptera from PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN2pNhu5oHdc"
      },
      "source": [
        "os.chdir('/content/sample_data')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w3nd58OoVxJ",
        "outputId": "2a213a99-baa2-4db0-fe24-69e7bf1cd036"
      },
      "source": [
        "! wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "! unzip hymenoptera_data.zip > /dev/null\n",
        "! cd hymenoptera_data && echo \"Downloaded and extracted dataset to: $(pwd)\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-04 22:13:19--  https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.32.204.34, 13.32.204.65, 13.32.204.93, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.32.204.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47286322 (45M) [application/zip]\n",
            "Saving to: ‘hymenoptera_data.zip’\n",
            "\n",
            "hymenoptera_data.zi 100%[===================>]  45.10M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-12-04 22:13:19 (366 MB/s) - ‘hymenoptera_data.zip’ saved [47286322/47286322]\n",
            "\n",
            "Downloaded and extracted dataset to: /content/sample_data/hymenoptera_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJJ9MT4Boj9y"
      },
      "source": [
        "data_dir = '/content/sample_data/hymenoptera_data'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nerI0l-kogS3"
      },
      "source": [
        "2) Define transforms\n",
        "\n",
        "Necessary Steps:\n",
        "- Do a random crop & rotation of the image\n",
        "- Convert image to `torch.Tensor`\n",
        "- Normalize image pixel values channel-wise\n",
        "\n",
        "*Note: The original ResNet architecture takes images that are $224 \\times 224 \\times c$.*  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQuC9J9Oos3d"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrORL4PspT8w"
      },
      "source": [
        "3) Create `DataLoader` to read the images in batches.\n",
        "\n",
        "*Note: For the pursposes of this experiment, we're only shuffling the training\n",
        "dataset.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sf08FcypUfu"
      },
      "source": [
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ('train', 'val')}\n",
        "dataloaders = {x: data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                  shuffle=(x =='train'), num_workers=4)\n",
        "              for x in ('train', 'val')}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ('train', 'val')}\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBpj7D2ypvAO"
      },
      "source": [
        "### Define training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ubiIE5zpxfE"
      },
      "source": [
        "num_epochs = 25\n",
        "num_classes = 2\n",
        "batch_size = 100\n",
        "learning_rate = 1e-4"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cxboJIup2Uy"
      },
      "source": [
        "### Define a CNN based on ResNet-34\n",
        "\n",
        "The original ResNet-34 architecture should look like this:\n",
        "```\n",
        "ResNet(\n",
        "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  (relu): ReLU(inplace=True)\n",
        "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
        "  (layer1): Sequential(\n",
        "    (0): BasicBlock(\n",
        "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (1): BasicBlock(\n",
        "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (2): BasicBlock(\n",
        "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "  )\n",
        "  (layer2): Sequential(\n",
        "    (0): BasicBlock(\n",
        "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (downsample): Sequential(\n",
        "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
        "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (1): BasicBlock(\n",
        "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (2): BasicBlock(\n",
        "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (3): BasicBlock(\n",
        "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "  )\n",
        "  (layer3): Sequential(\n",
        "    (0): BasicBlock(\n",
        "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (downsample): Sequential(\n",
        "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
        "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (1): BasicBlock(\n",
        "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (2): BasicBlock(\n",
        "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (3): BasicBlock(\n",
        "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (4): BasicBlock(\n",
        "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (5): BasicBlock(\n",
        "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "  )\n",
        "  (layer4): Sequential(\n",
        "    (0): BasicBlock(\n",
        "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (downsample): Sequential(\n",
        "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
        "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (1): BasicBlock(\n",
        "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (2): BasicBlock(\n",
        "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      (relu): ReLU(inplace=True)\n",
        "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "  )\n",
        "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
        ")\n",
        "```\n",
        "\n",
        "We will modify the fully-connected layers only (`model.fc`).\n",
        "\n",
        "Define a model that uses the ResNet-34 architecture and transfer learns the weights for the convolutional layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzvirgRCqSdE"
      },
      "source": [
        "class RaisinNet34(nn.Module):\n",
        "    \"\"\"A model that adapts the ResNet-34 architecture.\n",
        "\n",
        "    This network applies transfer learning to learn the parameters\n",
        "    of ResNet-34, and freezes those layers of the model. The classification\n",
        "    layer of the architecture is modified and will be retrained to \n",
        "    predict the desired number of output classes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"Creates a RaisinNet34 network.\n",
        "\n",
        "        Params:\n",
        "            num_classes - The number of output classes to predict\n",
        "        \"\"\"\n",
        "        super(RaisinNet34, self).__init__()\n",
        "        # Load a pre-trained ResNet-34 model and turn off autograd\n",
        "        # so its weights won't change.\n",
        "        architecture = resnet34(pretrained=True)\n",
        "        # Copy the convolutional layers of the model.\n",
        "        self.conv1 = architecture.conv1\n",
        "        self.bn1 = architecture.bn1\n",
        "        self.relu = architecture.relu\n",
        "        self.maxpool = architecture.maxpool\n",
        "        self.layer1 = architecture.layer1\n",
        "        self.layer2 = architecture.layer2\n",
        "        self.layer3 = architecture.layer3\n",
        "        self.layer4 = architecture.layer4\n",
        "        self.avgpool = architecture.avgpool\n",
        "        # Define a new block of fully-connected layers for the model.\n",
        "        in_ftrs = architecture.fc.in_features\n",
        "        self.classifier = nn.Linear(in_features=in_ftrs, out_features=num_classes, bias=True)\n",
        "        # self.classifier = nn.Sequential(\n",
        "        #     nn.Linear(in_features=in_ftrs, out_features=256, bias=True),\n",
        "        #     nn.ReLU(inplace=True),\n",
        "        #     nn.Dropout(p=0.5, inplace=False),\n",
        "        #     nn.Linear(in_features=256, out_features=256, bias=True),\n",
        "        #     nn.ReLU(inplace=True),\n",
        "        #     nn.Dropout(p=0.5, inplace=False),\n",
        "        #     nn.Linear(in_features=256, out_features=num_classes, bias=True)\n",
        "        # )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"Does a forward pass on an image x.\"\"\"\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "model = RaisinNet34(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I6YXvoOr4Bh",
        "outputId": "d3a1145b-1903-41ea-810e-4bf2c942f9b9"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RaisinNet34(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RV7Q8z0sAw4"
      },
      "source": [
        "Train `RaisinNet34` on Hymenoptera Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH9UHDGDr-Y9"
      },
      "source": [
        "def train(model, criterion, optimizer, scheduler, epochs=num_epochs):\n",
        "    model.train()\n",
        "    train_loader = dataloaders['train']\n",
        "    since = time.time()\n",
        "    num_steps = len(train_loader)\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        for i, (images, labels) in enumerate(train_loader, start=1):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Generate prediciton and evaluate\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Backpropagate loss and update weights\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Print epoch every 15 iterations\n",
        "            if i % 15 == 0:\n",
        "                print(f'Epoch [{epoch}/{num_epochs}], Step [{i}/{num_steps}], Loss: {loss.item():.6f}')\n",
        "    # Print training time\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY_xiKeasLHk",
        "outputId": "dd32f49d-5729-488d-a427-8569927ba60c"
      },
      "source": [
        "train(model, criterion, optimizer, scheduler=lr_scheduler, epochs=num_epochs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/25], Step [15/61], Loss: 0.619598\n",
            "Epoch [1/25], Step [30/61], Loss: 0.795685\n",
            "Epoch [1/25], Step [45/61], Loss: 1.197566\n",
            "Epoch [1/25], Step [60/61], Loss: 0.908640\n",
            "Epoch [2/25], Step [15/61], Loss: 0.750076\n",
            "Epoch [2/25], Step [30/61], Loss: 0.844411\n",
            "Epoch [2/25], Step [45/61], Loss: 0.732596\n",
            "Epoch [2/25], Step [60/61], Loss: 0.341045\n",
            "Epoch [3/25], Step [15/61], Loss: 0.451622\n",
            "Epoch [3/25], Step [30/61], Loss: 0.724378\n",
            "Epoch [3/25], Step [45/61], Loss: 0.684552\n",
            "Epoch [3/25], Step [60/61], Loss: 0.857587\n",
            "Epoch [4/25], Step [15/61], Loss: 0.546164\n",
            "Epoch [4/25], Step [30/61], Loss: 0.417341\n",
            "Epoch [4/25], Step [45/61], Loss: 0.549911\n",
            "Epoch [4/25], Step [60/61], Loss: 1.171716\n",
            "Epoch [5/25], Step [15/61], Loss: 1.043732\n",
            "Epoch [5/25], Step [30/61], Loss: 0.548061\n",
            "Epoch [5/25], Step [45/61], Loss: 0.521809\n",
            "Epoch [5/25], Step [60/61], Loss: 0.456636\n",
            "Epoch [6/25], Step [15/61], Loss: 0.738458\n",
            "Epoch [6/25], Step [30/61], Loss: 0.715598\n",
            "Epoch [6/25], Step [45/61], Loss: 0.714596\n",
            "Epoch [6/25], Step [60/61], Loss: 0.766200\n",
            "Epoch [7/25], Step [15/61], Loss: 0.706752\n",
            "Epoch [7/25], Step [30/61], Loss: 1.029284\n",
            "Epoch [7/25], Step [45/61], Loss: 0.301810\n",
            "Epoch [7/25], Step [60/61], Loss: 0.932220\n",
            "Epoch [8/25], Step [15/61], Loss: 0.925724\n",
            "Epoch [8/25], Step [30/61], Loss: 0.528145\n",
            "Epoch [8/25], Step [45/61], Loss: 0.649266\n",
            "Epoch [8/25], Step [60/61], Loss: 1.057803\n",
            "Epoch [9/25], Step [15/61], Loss: 0.433295\n",
            "Epoch [9/25], Step [30/61], Loss: 0.646973\n",
            "Epoch [9/25], Step [45/61], Loss: 0.845501\n",
            "Epoch [9/25], Step [60/61], Loss: 0.344157\n",
            "Epoch [10/25], Step [15/61], Loss: 0.676329\n",
            "Epoch [10/25], Step [30/61], Loss: 0.959298\n",
            "Epoch [10/25], Step [45/61], Loss: 0.712582\n",
            "Epoch [10/25], Step [60/61], Loss: 0.765899\n",
            "Epoch [11/25], Step [15/61], Loss: 0.649054\n",
            "Epoch [11/25], Step [30/61], Loss: 0.742094\n",
            "Epoch [11/25], Step [45/61], Loss: 0.862814\n",
            "Epoch [11/25], Step [60/61], Loss: 0.637901\n",
            "Epoch [12/25], Step [15/61], Loss: 0.508193\n",
            "Epoch [12/25], Step [30/61], Loss: 0.729652\n",
            "Epoch [12/25], Step [45/61], Loss: 0.709034\n",
            "Epoch [12/25], Step [60/61], Loss: 0.637229\n",
            "Epoch [13/25], Step [15/61], Loss: 0.609208\n",
            "Epoch [13/25], Step [30/61], Loss: 0.581797\n",
            "Epoch [13/25], Step [45/61], Loss: 0.530554\n",
            "Epoch [13/25], Step [60/61], Loss: 0.734747\n",
            "Epoch [14/25], Step [15/61], Loss: 0.708993\n",
            "Epoch [14/25], Step [30/61], Loss: 1.265631\n",
            "Epoch [14/25], Step [45/61], Loss: 0.971934\n",
            "Epoch [14/25], Step [60/61], Loss: 0.538609\n",
            "Epoch [15/25], Step [15/61], Loss: 0.714341\n",
            "Epoch [15/25], Step [30/61], Loss: 0.653144\n",
            "Epoch [15/25], Step [45/61], Loss: 0.676235\n",
            "Epoch [15/25], Step [60/61], Loss: 0.612506\n",
            "Epoch [16/25], Step [15/61], Loss: 0.634223\n",
            "Epoch [16/25], Step [30/61], Loss: 0.782328\n",
            "Epoch [16/25], Step [45/61], Loss: 0.805504\n",
            "Epoch [16/25], Step [60/61], Loss: 0.586797\n",
            "Epoch [17/25], Step [15/61], Loss: 0.554723\n",
            "Epoch [17/25], Step [30/61], Loss: 0.452396\n",
            "Epoch [17/25], Step [45/61], Loss: 0.555815\n",
            "Epoch [17/25], Step [60/61], Loss: 0.797974\n",
            "Epoch [18/25], Step [15/61], Loss: 0.564136\n",
            "Epoch [18/25], Step [30/61], Loss: 0.573301\n",
            "Epoch [18/25], Step [45/61], Loss: 0.887387\n",
            "Epoch [18/25], Step [60/61], Loss: 0.603092\n",
            "Epoch [19/25], Step [15/61], Loss: 0.443742\n",
            "Epoch [19/25], Step [30/61], Loss: 0.667427\n",
            "Epoch [19/25], Step [45/61], Loss: 0.506367\n",
            "Epoch [19/25], Step [60/61], Loss: 0.777226\n",
            "Epoch [20/25], Step [15/61], Loss: 0.461933\n",
            "Epoch [20/25], Step [30/61], Loss: 0.692791\n",
            "Epoch [20/25], Step [45/61], Loss: 0.824975\n",
            "Epoch [20/25], Step [60/61], Loss: 1.018372\n",
            "Epoch [21/25], Step [15/61], Loss: 0.701899\n",
            "Epoch [21/25], Step [30/61], Loss: 0.818830\n",
            "Epoch [21/25], Step [45/61], Loss: 0.639610\n",
            "Epoch [21/25], Step [60/61], Loss: 0.780420\n",
            "Epoch [22/25], Step [15/61], Loss: 0.769525\n",
            "Epoch [22/25], Step [30/61], Loss: 0.732395\n",
            "Epoch [22/25], Step [45/61], Loss: 0.942400\n",
            "Epoch [22/25], Step [60/61], Loss: 0.843257\n",
            "Epoch [23/25], Step [15/61], Loss: 0.718698\n",
            "Epoch [23/25], Step [30/61], Loss: 0.984873\n",
            "Epoch [23/25], Step [45/61], Loss: 0.666132\n",
            "Epoch [23/25], Step [60/61], Loss: 0.820742\n",
            "Epoch [24/25], Step [15/61], Loss: 0.697867\n",
            "Epoch [24/25], Step [30/61], Loss: 0.788506\n",
            "Epoch [24/25], Step [45/61], Loss: 0.598076\n",
            "Epoch [24/25], Step [60/61], Loss: 0.759604\n",
            "Epoch [25/25], Step [15/61], Loss: 0.801296\n",
            "Epoch [25/25], Step [30/61], Loss: 0.560535\n",
            "Epoch [25/25], Step [45/61], Loss: 0.738763\n",
            "Epoch [25/25], Step [60/61], Loss: 0.725316\n",
            "Training complete in 1m 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7x97u2Ns3Ce"
      },
      "source": [
        "### Evaluate the effectiveness of `RaisinNet34`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlsPDdqisoT8",
        "outputId": "43195fb7-27a3-4e06-ee7a-9db01d84683f"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in dataloaders['val']:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "    print(f'Test Accuracy of RaisinNet34: {(100*(correct/total)):.6f}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of RaisinNet34: 54.901961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8otYsEf0Boh"
      },
      "source": [
        "# Clean up dataset\n",
        "! rm -rf /content/sample_data/hymenoptera_data*"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}