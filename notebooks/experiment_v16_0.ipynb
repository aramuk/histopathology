{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python37264bit24537231cb884bb3b902095b5dcd77a6",
      "display_name": "Python 3.7.2 64-bit"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASLrIp-LNeoD"
      },
      "source": [
        "# Trainers\n",
        "\n",
        "Designing a training loop for learning a complex dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywnbqxbkP4S8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils as utils\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from lib.dataset import PCam\n",
        "from lib.evaluate import evaluate\n",
        "from lib.models import Veggie16\n",
        "from lib.train import train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wC2rg5LTtGF"
      },
      "source": [
        "DATASET_PATH = '../data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9J7U_VaTlxZ"
      },
      "source": [
        "image_dir = os.path.join(DATASET_PATH, 'train')\n",
        "csv_path = os.path.join(DATASET_PATH, 'train_labels.csv')\n",
        "pcam_dataset = PCam(image_dir, csv_path, \n",
        "                    transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.5,),(0.5,))\n",
        "                    ]))\n",
        "print(len(pcam_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na4D7EgDWp7h",
        "outputId": "d44fa174-4acf-4180-a0a8-f1a53a5de4c8"
      },
      "source": [
        "train_set, val_set = utils.data.random_split(pcam_dataset, [154000, 66025])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH4_h9wjUEQd"
      },
      "source": [
        "train_loader = utils.data.DataLoader(train_set, batch_size=4, num_workers=0)\n",
        "val_loader = utils.data.DataLoader(val_set, batch_size=4, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "num_classes = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Veggie16(2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = train(model, train_loader, device, criterion, optimizer, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.semilogy()\n",
        "plt.plot(tuple(range(num_epochs)), losses, 'b-')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylable('Cross Entropy Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score, accuracy, loss = evaluate(model, val_loader, device, criterion)\n",
        "print('Evaluating Veggie16 on Validation set:')\n",
        "print('F1-Score:', score)\n",
        "print('Accuracy:', accuracy)\n",
        "print('Loss:', loss)"
      ]
    }
  ]
}