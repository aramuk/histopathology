{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Veggie16 Experiment 1\n\nThe final experiment conducted using the proposed Veggie16 model. This notebook has been adapted to run on the Kaggle kernel.\n\nThe experiment aims to maximize the potential of the Veggie16 architecture, building on takeaways from previous experiments. The goal is to achieve the best possible parameterization of the Veggie16 architecture."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"import os\n\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils as utils\nfrom torchvision import datasets, transforms\n\nimport histopathology as hcd # Helper code stored as Kaggle Script","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Path to the Histopathologic Cancer Detection dataset, preloaded into this Kaggle kernel."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":false},"cell_type":"code","source":"DATASET_PATH = '/kaggle/input/histopathologic-cancer-detection'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Relevant Model Decisions:\n\n**Transforms:**\n\n1. Morphological closing\n2. Random resized crop to 224x224\n3. Random horizontal flip\n4. `ToTensor()`\n5. Channel-wise mean normalization \n\n**Model:** Veggie16 network adapted from VGG-16 architecture. Convolutional layers pretrained and frozen.\n\n**Criterion:** Cateorical Cross-Entropy\n\n**Optimizer:** Adam\n\n**Training Hyperparameters:** (See Below)"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Train/validation split distribution\ntrain_pct = 80\n# Training parameters\nbatch_size = 50\nnum_epochs = 25\n# Optimizer parameters\nlearning_rate = 1e-4\n# For mean normalization. Computed over the dataset.\nrgb_means = [0.70025474, 0.54378763, 0.6961546]\nrgb_stds = [0.23917262, 0.28227101, 0.2156419]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transform, Split, and Load the Dataset\n\nGet the PCam dataset (Histopathologic Cancer Detection) and apply the transforms."},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"image_dir = os.path.join(DATASET_PATH, 'train')\ncsv_path = os.path.join(DATASET_PATH, 'train_labels.csv')\npcam_dataset = hcd.dataset.PCam(image_dir, csv_path, \n                    transforms.Compose([\n                        hcd.transforms.ToClosed(),\n                        transforms.RandomRotation(90),\n                        transforms.CenterCrop(48),\n                        transforms.ToTensor(),\n                        hcd.transforms.ToNormalized(rgb_means, rgb_stds),\n                    ]))\nprint(f'PCam has {len(pcam_dataset)} samples')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Partition the dataset into a training and validation set."},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train_size = int(train_pct/100 * len(pcam_dataset))\nval_size = len(pcam_dataset) - train_size\nprint(f'Splitting PCam {train_pct}%/{100-train_pct}% into train/validation sets')\n# Seed PRNG with the answer to the Ultimate Question of Life, the Universe, and Everything\ntrain_set, val_set = utils.data.random_split(pcam_dataset, \n                                             [train_size, val_size],\n                                             generator=torch.Generator().manual_seed(42))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create Pytorch Dataloaders for each dataset."},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train_loader = utils.data.DataLoader(train_set, batch_size=batch_size, num_workers=4, shuffle=False)\nval_loader = utils.data.DataLoader(val_set, batch_size=batch_size, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use GPU for Training"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint('Device:', device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define the Model, Criterion, and Optimizer\n\nIf using the Kaggle kernel, turn on the internet to run this cell so it can download the pretrained VGG-16 weights. "},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"model = hcd.models.Veggie16(pretrained=True, freeze_weights=False).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create a `Trainer` and Load Weights"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"trainer = hcd.training.Trainer(model, device, train_loader, val_loader)\n# trainer.load_checkpoint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Model on Training Partition"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"res = trainer.train(criterion, optimizer, num_epochs=num_epochs, output_freq=1000)\nlosses_tr, losses_va, accs_tr, accs_va = res","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot Loss and Accuracy over the epochs."},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"fig, ax = hcd.evaluation.plot_loss_and_accuracy(losses_tr, accs_tr)\nplt.savefig('/kaggle/working/rates.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\neps = np.arange(1, num_epochs+1)\nax[0].plot(eps, np.array(losses_tr)/len(train_loader), 'r-', label='Train Loss')\nax[0].plot(eps, np.array(losses_va)/len(val_loader), 'g-', label='Validation Loss')\nax[0].set_ylabel('Loss per Batch')\nax[0].set_xlabel('Epoch')\nax[0].legend()\nax[0].set_title(f'{model.__class__.__name__} Loss/Batch over 25 Epochs')\nax[1].plot(eps, np.array(accs_tr), 'b-', label='Train Accuracy')\nax[1].plot(eps, np.array(accs_va), 'y-', label='Validation Accuracy')\nax[1].set_ylabel('Accuracy')\nax[1].set_xlabel('Epoch')\nax[1].legend()\nax[1].set_title(f'{model.__class__.__name__} Accuracy over 25 Epochs')\nplt.savefig('./veggie16_revised_rates.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate Model on Validation Partition"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"score, accuracy, loss = trainer.evaluate(criterion)\nprint(f'Evaluating {model.__class__.__name__} on validation set:')\nprint('-'*30)\nprint('F1-Score:', score)\nprint('Accuracy:', accuracy)\nprint('Loss:', loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save Trained Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\ndef roc(model, data_loader, device, subsample=1.0):\n    \"\"\"Estimate the ROC curve and its integral for the model on a dataset.\n    \n    Args:\n        model: A PyTorch model.\n        data_loader: A PyTorch DataLoader (shuffled).\n        device: Device for running model.\n        subsample: The number of samples to use when estimating the ROC curve.\n\n    Return:\n        auc: Area under the ROC curve.\n        fpr: False positive rate of model at various thresholds.\n        tpr: True positive rate of model at same thresholds as FPR.\n        thresholds: Thresholds at which the model was decided\n    \"\"\"\n    y_true = []\n    y_hat = []\n    with torch.no_grad():\n        num_batches = len(data_loader)\n        sample_size = int(subsample * num_batches)\n        \n        for i, (images, labels) in enumerate(data_loader, start=1):\n            if i > sample_size:\n                break\n            images = images.to(device)\n            labels = labels.long().flatten().to(device)\n            # Forward pass and get predicted label\n            outputs = model(images)\n            probabilities = model.log_softmax(outputs)\n            # Update\n            y_hat.extend(probabilities[:,1].tolist())\n            y_true.extend(labels.tolist())\n            if i % 100 == 0:\n                print(f'Computed predictions for sample [{i}/{sample_size}]')\n    fpr, tpr, thresholds = roc_curve(y_true, y_hat)\n    auc = np.trapz(tpr, fpr)\n    return auc, fpr, tpr, thresholds\n\ndef plot_roc(fpr, tpr, auc, model_name):\n    \"\"\"Plot ROC curve for a model.\n    \n    Args:\n        fpr: False positive rate at various thresholds.\n        tpr: True positive rate at same thresholds as fpr.\n        auc: Computer area under the ROC curve.\n        model_name: The name of the model.\n    \"\"\"\n    plt.figure()\n    # ROC Curve\n    plt.plot(fpr, tpr, 'b-', lw=2, label=f'ROC curve (Area = {auc:.4f})')\n    # No discrimination line\n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.plot(fpr, tpr)\n    # Scale axes\n    plt.xlim([-0.05, 1.0])\n    plt.ylim([0.0, 1.05])\n    # Labels\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend(loc=\"lower right\")\n    plt.title(f'Received Operating Characteristic Curve for {model_name}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc, fpr, tpr, thresholds = roc(model, train_loader, device)\nplot_roc(fpr, tpr, auc, model.__class__.__name__)\nplt.savefig('./veggie16_revised_train_roc.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc, fpr, tpr, thresholds = roc(model, val_loader, device)\nplot_roc(fpr, tpr, auc, model.__class__.__name__)\nplt.savefig('./veggie16_revised_val_roc.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\ndef predict_to_csv(model, unlabeled_loader, device, col_names, csv_path, batch_size=50):\n    \"\"\"Saves model predictions to a CSV file.\n    \n    Args:\n        model: A PyTorch model.\n        unlabeled_loader: A PyTorch DataLoader that returns only images.\n        device: Device for running model.\n        col_names: Column names for the output csv.\n        csv_path: Output path of csv.\n    \"\"\"\n    if not os.path.exists(os.path.dirname(csv_path)):\n        raise ValueError(f'Attempted to save predictions invalid directory: {csv_path}')\n    model.eval()\n    with torch.no_grad():\n        with open(csv_path, 'w') as csvfile:\n            predictions_writer = csv.writer(csvfile)\n            predictions_writer.writerow(['id','label'])\n\n            num_steps = len(unlabeled_loader)\n            for i, images in enumerate(unlabeled_loader):\n                images = images.to(device)\n                outputs = model(images)\n                probabilities = model.log_softmax(outputs)\n                predictions = torch.argmax(probabilities, dim=1)\n\n                for j, prob in enumerate(predictions):\n                    idx = i*batch_size + j\n                    predictions_writer.writerow([os.path.splitext(col_names[idx])[0], \n                                                 prob.item()])\n                if i % 100 == 0:\n                    print(f'Predictions written for batch [{i}/{num_steps}]')\n    print(f'Saved model predictions to: {csv_path}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL\nfrom torch.utils.data import Dataset\nclass UnlabeledPCam(Dataset):\n    \"\"\"The Patch Camelyon (PCam) dataset, without ground truth labels [1].\n    \n    Retrieved from https://www.kaggle.com/c/histopathologic-cancer-detection/.\n\n    [1] B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling. \"Rotation \n        Equivariant CNNs for Digital Pathology\". arXiv:1806.03962\n    \"\"\"\n\n    def __init__(self, image_dir, transform=None):\n        \"\"\"Create a PyTorch dataset of images from PCam.\n\n        Args:\n            image_dir: Folder with image data in file system.\n            transform: Transforms to apply before loading.\n        \"\"\"\n        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):\n            raise ValueError(f'Proposed image directory {image_dir} is not on this file system.')\n        self.image_dir = image_dir\n        self.transform = transform\n        self.image_paths = os.listdir(self.image_dir)\n        self.num_samples = len(self.image_paths)\n\n    def __len__(self):\n        \"\"\"Returns the length of the unlabeled PCam dataset.\"\"\"\n        return self.num_samples\n\n    def __getitem__(self, idx):\n        \"\"\"Get the image at a given index in the PCam dataset.\"\"\"\n        if torch.is_tensor(idx):\n            idx = idx.to_list()\n        image_path = os.path.join(self.image_dir, self.image_paths[idx])\n        image = PIL.Image.open(image_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(image_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_dir = os.path.join(DATASET_PATH, 'test')\ntest_set = UnlabeledPCam(image_dir,\n                        transforms.Compose([\n                            hcd.transforms.ToClosed(),\n                            transforms.CenterCrop(48),\n                            transforms.ToTensor(),\n                            hcd.transforms.ToNormalized(rgb_means, rgb_stds)]))\ntest_loader = utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_to_csv(model, test_loader, device, test_set.image_paths, \n               './preds_veggie16_revised.csv', batch_size=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"trainer.save_final_model()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}